flux: [efiitg_gb, efeitg_gb_div_efiitg_gb]

data:
    train: /path/to/train_data.pkl
    validation: /path/to/valid_data.pkl
    test: /path/to/test_data.pkl
save_paths:
    plots: /path/to/plots
    outputs: /path/to/outputs

retrain_classifier: True
retrain_regressor: True


# Use pre-trained model or train from scratch
pretrained:
    Classifier:
        efiitg_gb:
            save_path: /path/to/pretrained/itg_class.pt
            trained: True
        efetem_gb:
            save_path: /path/to/pretrained/etg_class.pt
            trained: True
        efeetg_gb:
            save_path: /path/to/pretrained/tem_class.pt
            trained: True


    Regressor:
        efiitg_gb:
            save_path: /path/to/pretrained/itg_reg.pt
            trained: True
        efetem_gb:
            save_path: /path/to/pretrained/etg_reg.pt
            trained: True
        efeetg_gb:
            save_path: /path/to/pretrained/tem_reg.pt
            trained: True
        pfiitg_gb_div_efiitg_gb:
            save_path: /path/to/pretrained/pfitg_reg.pt
            trained: True 

hyperparams:
    train_size: 20_000
    valid_size: 10_000
    test_size:  10_000
    candidate_size: 10_000 
    batch_size: 256
    lambda: 1
    buffer_size: 500

logging_level: DEBUG
# Pipeline parameters
iterations: 10
initial_epochs: 50
MC_dropout_runs: 50
keep_prob: 0.25 
patience: 20
learning_rate: 0.001
dropout_rate: 0.1
acquisition: add_uncertainties #individual_uncertainty, random, distance_penalty

sample_size_debug: 0.1

# if training models from scratch, the hyperparameters below are used
train_epochs: 30
train_patience: 15

