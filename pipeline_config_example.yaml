flux: [efiitg_gb, efeitg_gb_div_efiitg_gb]

data:
    train: /path/to/train_data.pkl
    validation: /path/to/valid_data.pkl
    test: /path/to/test_data.pkl
save_paths:
    plots: /path/to/plots
    outputs: /path/to/outputs

retrain_classifier: False
retrain_regressor: True


# Use pre-trained model or train from scratch
pretrained:
  Classifier:
      efiitg_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/ITGclassifier.pt"
          trained: False
      efetem_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/TEMclassifier.pt"
          trained: False
      efeetg_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/ETGclassifier.pt"
          trained: False
  Regressor:
      efiitg_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/ITGregressor.pt"
          trained: False
      efetem_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/TEMclassifier.pt"
          trained: False
      efeetg_gb:
          save_path: "/home/ir-zani1/rds/rds-ukaea-ap001/ir-zani1/qualikiz/UKAEAGroupProject/saved/ETGclassifier.pt"
          trained: True

hyperparams:
    train_size: 20_000
    valid_size: 10_000
    test_size:  10_000
    candidate_size: 10_000 
    batch_size: 256
    lambda: 1
    buffer_size: 500
    model_size: 'deep' # 'shallow_wide' #deep

logging_level: DEBUG
# Pipeline parameters
iterations: 20
initial_epochs: 30
MC_dropout_runs: 5
keep_prob: 0.25 
patience: 20
learning_rate: 0.001
acquisition: add_uncertainties #individual_uncertainty, random, distance_penalty

# if training models from scratch, the hyperparameters below are used
